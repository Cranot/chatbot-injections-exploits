💬🤖💉●～* # Chatbot Injections & Exploits🐱‍💻
Injections and exploits for ChatBots, a curated list of prompt commands

Welcome to the "Chatbot Injections & Exploits". This is a collection of injections, exploits, prompts or other commands to "trick" ChatBot.

As the pace of AI developments and adoption progress rapidly, we must also be aware of flaws & vulnerabilites of these systems so we can be better protected.

## What are ChatBot Injections?
Chatbot exploit prompts or injections are commands or questions that are designed to exploit vulnerabilities in the chatbot system. These prompts can be used to make chatbots behave abnormaly, or expose information they shouldnt otherwise.

## What types of attacks exists?

### Command injection keywords:
Command injection is a type of attack that allows an attacker to execute arbitrary commands on a target system. Chat bots may be vulnerable to command injection if they process user input as commands without proper sanitization. Common command injection keywords include "&&", "|", and ";".

### Emojis: Emojis can be used to obfuscate malicious code or trigger unintended actions by the chat bot. For example, the "bomb" emoji 🧨 could be used to execute a command, or the "fire" emoji 🔥 could be used to delete data for example as emojis can have hidden meanings based on the training set and other factors.

### Social engineering tactics:
Social engineering is the practice of using psychological manipulation to trick people into divulging sensitive information or performing actions they wouldn't normally do. Social engineering tactics could be used to trick a chat bot into revealing sensitive information, executing unintended actions, or following malicious links.

### Hidden characters:
Hidden characters like spaces, tabs, and newlines can be used to bypass input validation and execute unintended actions. For example, adding a newline character at the end of a message could cause the chat bot to interpret the next message as a command.
